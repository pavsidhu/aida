{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8406b211848441a0915429d114adb913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0417c0e32f8424cb94a10adc32b0330",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_012d34f717c3484ba862c94eddbf115a",
              "IPY_MODEL_fcf27a85f52546deb50c6fe4680e2f3d"
            ]
          }
        },
        "c0417c0e32f8424cb94a10adc32b0330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "012d34f717c3484ba862c94eddbf115a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31263196fa004e529693c3ef506b538c",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57432ff14c3748f7b8f0641594569559"
          }
        },
        "fcf27a85f52546deb50c6fe4680e2f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ed494d9242754c329fa2eb92efa2c3aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 5.35MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f60b074177104603bc6032101be54ab1"
          }
        },
        "31263196fa004e529693c3ef506b538c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57432ff14c3748f7b8f0641594569559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed494d9242754c329fa2eb92efa2c3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f60b074177104603bc6032101be54ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irrvlO-YwA3T",
        "colab_type": "text"
      },
      "source": [
        "# Personality Analysis using a Bimodel LSTM Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHsTgz72xfhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "f2477f78-dfff-4a21-81a5-7f4f78c0c830"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\r\u001b[K     |▊                               | 10kB 28.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 19.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=b50680a7962a002308351fab1270e09c39c0faf2ff3f45c050b9f4377b2f32b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcOrNDCZwA3y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80086329-168b-47a8-b0bd-70ce156678fd"
      },
      "source": [
        "import warnings\n",
        "\n",
        "import pandas\n",
        "import torch\n",
        "from google.colab import drive, files\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn, optim, tensor\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils import data\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "DRIVE_PATH = \"/content/drive/My Drive/aida\"\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B817lBiGwA38",
        "colab_type": "text"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_F50nsJwA39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8406b211848441a0915429d114adb913",
            "c0417c0e32f8424cb94a10adc32b0330",
            "012d34f717c3484ba862c94eddbf115a",
            "fcf27a85f52546deb50c6fe4680e2f3d",
            "31263196fa004e529693c3ef506b538c",
            "57432ff14c3748f7b8f0641594569559",
            "ed494d9242754c329fa2eb92efa2c3aa",
            "f60b074177104603bc6032101be54ab1"
          ]
        },
        "outputId": "2bfa082a-5237-4250-df90-39690f9b8286"
      },
      "source": [
        "MY_PERSONALITY_PATH = DRIVE_PATH + \"/mypersonality.csv\"\n",
        "TRAITS = [\"sEXT\", \"sNEU\", \"sAGR\", \"sCON\", \"sOPN\"]\n",
        "\n",
        "# Portion of the dataset to use for testing\n",
        "TEST_SPLIT_SIZE = 0.2\n",
        "\n",
        "# Portion of the training set to use for validation\n",
        "VALIDATION_SPLIT_SIZE = 0.1\n",
        "\n",
        "def load_my_personality_dataset(path=MY_PERSONALITY_PATH):\n",
        "    \"\"\"Loads the texts and traits from the MyPersonality dataset\"\"\"\n",
        "\n",
        "    data = pandas.read_csv(path, encoding=\"latin1\")\n",
        "    return data[[\"STATUS\", *TRAITS]]\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8406b211848441a0915429d114adb913",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_qbvYdxj7gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyPersonalityDataset(data.Dataset):\n",
        "    \"\"\"Stores the MyPersonality dataset\"\"\"\n",
        "\n",
        "    MIN_LABEL_VALUE = 1\n",
        "    MAX_LABEL_VALUE = 5\n",
        "\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = [torch.tensor(self.tokenize(text)) for text in texts]\n",
        "        self.labels = [torch.tensor(self.normalize(label)) for label in labels]\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        text = text.lower()\n",
        "        return tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "    def normalize(self, label):\n",
        "        return (label - self.MIN_LABEL_VALUE) / (self.MAX_LABEL_VALUE - self.MIN_LABEL_VALUE)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.texts[index], self.labels[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISPdKB4Klqdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = load_my_personality_dataset(MY_PERSONALITY_PATH)\n",
        "\n",
        "def pad_collate(batch):\n",
        "    \"\"\"Pads the dataset so tokens are the same length\"\"\"\n",
        "\n",
        "    (tokens, labels) = zip(*batch)\n",
        "    \n",
        "    padded_tokens = pad_sequence(tokens, batch_first=True, padding_value=0)\n",
        "    token_lengths = [len(token) for token in tokens]\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return padded_tokens, token_lengths, labels\n",
        "\n",
        "def generate_dataset(trait, params):\n",
        "    \"\"\"Generates the training and validation sets for a given trait in the MyPersonality dataset\"\"\"\n",
        "\n",
        "    text, labels = dataset[\"STATUS\"], dataset[trait]\n",
        "\n",
        "    # Split dataset into training and test sets\n",
        "    train_text, test_text, train_labels, test_labels = train_test_split(\n",
        "        text, labels, test_size=TEST_SPLIT_SIZE, random_state=0\n",
        "    )\n",
        "\n",
        "    # Split training into training and validation sets\n",
        "    train_text, val_text, train_labels, val_labels = train_test_split(\n",
        "        text, labels, test_size=VALIDATION_SPLIT_SIZE, random_state=0\n",
        "    )\n",
        "\n",
        "    training_set = MyPersonalityDataset(train_text[:500], train_labels[:500])\n",
        "    training_generator = data.DataLoader(training_set, collate_fn=pad_collate, **params)\n",
        "\n",
        "    validation_set = MyPersonalityDataset(val_text, val_labels)\n",
        "    validation_generator = data.DataLoader(validation_set, collate_fn=pad_collate, **params)\n",
        "\n",
        "    test_set = MyPersonalityDataset(test_text, test_labels)\n",
        "    test_generator = data.DataLoader(test_set, collate_fn=pad_collate, **params)\n",
        "    \n",
        "    return training_generator, validation_generator, test_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlSd46VpwA4C",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2VtzlecwA4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    \"\"\"An attention layer used by the LSTM\"\"\"\n",
        "    def __init__(self, attention_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attention = self.generate_attention_vector(attention_size, 1)\n",
        "\n",
        "        # Use GPU if available\n",
        "        self.to(device)\n",
        "\n",
        "    def generate_attention_vector(self, *size):\n",
        "        out = torch.FloatTensor(*size).to(device)\n",
        "        torch.nn.init.xavier_normal_(out)\n",
        "        return out\n",
        "        \n",
        "    def forward(self, x_in):\n",
        "        attention_score = torch.matmul(x_in, self.attention).squeeze()\n",
        "        attention_score = nn.functional.softmax(attention_score).view(x_in.size(0), x_in.size(1), 1)\n",
        "        scored_x = x_in * attention_score\n",
        "\n",
        "        condensed_x = torch.sum(scored_x, dim=1)\n",
        "\n",
        "        return condensed_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UshANU6vwA4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LstmModel(nn.Module):\n",
        "    \"\"\"LSTM model to predict personality\"\"\"\n",
        "\n",
        "    def __init__(self, emedding_dim=768, hidden_dim=1536, output_dim=1):\n",
        "        super(LstmModel, self).__init__()\n",
        "        \n",
        "        # Model structure\n",
        "        self.word_embeddings = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "        self.lstm_1 = nn.LSTM(emedding_dim, hidden_dim, batch_first=True)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        self.output = nn.Sequential(nn.Linear(hidden_dim, output_dim), nn.Sigmoid())\n",
        "        \n",
        "        # Use GPU if available\n",
        "        self.to(device)\n",
        "    \n",
        "    def forward(self, tokens):\n",
        "        emeddings = self.word_embeddings(tokens)[0]\n",
        "        lstm_output = self.lstm_1(emeddings)[0]\n",
        "        attention_output = self.attention(lstm_output)\n",
        "        result = self.output(attention_output)\n",
        "\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umkuMf60wA4M",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "o0obBJMBwA4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_function, optimizer, data_generator):\n",
        "    \"\"\"Trains the model given a training set\"\"\"\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        losses = []\n",
        "\n",
        "        for padded_tokens, token_lengths, labels in data_generator:\n",
        "            model.zero_grad()\n",
        "\n",
        "            padded_tokens = padded_tokens.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            model_trait_scores = model(padded_tokens)\n",
        "            \n",
        "            loss = loss_function(model_trait_scores, labels)\n",
        "            losses.append(float(loss))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        average_loss = np.mean(losses)\n",
        "\n",
        "        print(f\"Epoch: {epoch} | Avg Loss: {average_loss}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHAT4y3fwA4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c571f75d-9ccd-4236-bd64-9a57f8c3b294"
      },
      "source": [
        "\"\"\"Traings the models for all traits\"\"\"\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.0001\n",
        "max_epochs = 50\n",
        "dataloader_params = {\n",
        "    \"batch_size\": 16,\n",
        "    \"shuffle\": False,\n",
        "    \"num_workers\": 6\n",
        "}\n",
        "\n",
        "# Saves models if set to true\n",
        "save_models = True\n",
        "\n",
        "print(\"Begin Training...\")\n",
        "\n",
        "for trait in TRAITS:\n",
        "    model = LstmModel()\n",
        "    loss_function = nn.BCELoss()\n",
        "    optimizer = optim.Adam((p for p in model.parameters() if p.requires_grad), lr=learning_rate)\n",
        "\n",
        "    training_generator, validation_generator, test_generator = generate_dataset(trait, dataloader_params)\n",
        "\n",
        "    print(f\"\\nTraining {trait}:\")\n",
        "\n",
        "    train(model, loss_function, optimizer, training_generator)\n",
        "    evaluate(model, test_generator)\n",
        "\n",
        "    if save_models:\n",
        "        torch.save(model.state_dict(), f\"{DRIVE_PATH}/{trait}_model_state.pth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin Training...\n",
            "\n",
            "Training sEXT:\n",
            "Epoch: 0 | Avg Loss: 0.6757059395313263\n",
            "Epoch: 1 | Avg Loss: 0.6767847668379545\n",
            "Epoch: 2 | Avg Loss: 0.6711772419512272\n",
            "Epoch: 3 | Avg Loss: 0.6713369693607092\n",
            "Epoch: 4 | Avg Loss: 0.6683808341622353\n",
            "Epoch: 5 | Avg Loss: 0.6566351186484098\n",
            "Epoch: 6 | Avg Loss: 0.6355478540062904\n",
            "Epoch: 7 | Avg Loss: 0.6085198409855366\n",
            "Epoch: 8 | Avg Loss: 0.6021594144403934\n",
            "Epoch: 9 | Avg Loss: 0.6012177541851997\n",
            "Epoch: 10 | Avg Loss: 0.5923305070027709\n",
            "Epoch: 11 | Avg Loss: 0.5847394037991762\n",
            "Epoch: 12 | Avg Loss: 0.5801328886300325\n",
            "Epoch: 13 | Avg Loss: 0.5804642252624035\n",
            "Epoch: 14 | Avg Loss: 0.5813030395656824\n",
            "Epoch: 15 | Avg Loss: 0.5806224681437016\n",
            "Epoch: 16 | Avg Loss: 0.5848505068570375\n",
            "Epoch: 17 | Avg Loss: 0.5822806693613529\n",
            "Epoch: 18 | Avg Loss: 0.582785808481276\n",
            "Epoch: 19 | Avg Loss: 0.5795560879632831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z8YL0LdTCKH",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiVMLRecTB3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, data_generator):\n",
        "    \"\"\"Evaluates a model given a validation/test set\"\"\"\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for padded_tokens, token_lengths, labels in data_generator:\n",
        "            padded_tokens = padded_tokens.to(device)\n",
        "            \n",
        "            model_trait_scores = model(padded_tokens)            \n",
        "            model_trait_scores = model_trait_scores.cpu()\n",
        "\n",
        "            errors = mean_absolute_error(labels, model_trait_scores)\n",
        "        \n",
        "    accuracy = 1 - np.mean(errors)\n",
        "    print(\"Accuracy: \" + str(accuracy) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIuKFXoNupQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "0a0ebf96-2cdb-408c-fded-b28e719cf058"
      },
      "source": [
        "\"\"\"Evaluates saved models\"\"\"\n",
        "\n",
        "# Hyperparameters\n",
        "dataloader_params = {\n",
        "    \"batch_size\": 16,\n",
        "    \"shuffle\": False,\n",
        "    \"num_workers\": 6\n",
        "}\n",
        "\n",
        "print(\"Begin Evaluation...\\n\")\n",
        "\n",
        "training_generator, validation_generator, test_generator = generate_dataset(trait, dataloader_params)\n",
        "\n",
        "for trait in TRAITS:\n",
        "    model = LstmModel()\n",
        "    model.load_state_dict(torch.load(f\"{DRIVE_PATH}/{trait}_model_state.pth\"))\n",
        "    model.eval()\n",
        "\n",
        "    print(\"Evaluating \" + trait)\n",
        "\n",
        "    evaluate(model, test_generator)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin Evaluation...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-26c8e6fc57f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrait\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTRAITS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLstmModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DRIVE_PATH}/{trait}_model_state.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c287639d49d3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, emedding_dim, hidden_dim, output_dim)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Model structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertPooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     def forward(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     def forward(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertIntermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_act\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACT2FN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_act\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}